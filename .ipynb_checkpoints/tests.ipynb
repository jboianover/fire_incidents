{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38364bitafc563adc08b45599aa826ac5a190a64",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from configparser import ConfigParser\n",
    "import ast\n",
    "\n",
    "\n",
    "def get_param(section, key):\n",
    "    #use this for jupyter notebook\n",
    "    config_file = os.path.join(r'C:\\GitHub\\fire_incidents', 'config.ini')\n",
    "    \n",
    "    #use this for .py script execution\n",
    "    #config_file = os.path.join(Path(os.path.dirname(os.path.abspath(__file__))), 'config.ini')\n",
    "\n",
    "    config = ConfigParser()\n",
    "    config.read(config_file)\n",
    "\n",
    "    return config[section][key]\n",
    "    \n",
    "def get_dictionary(filename):\n",
    "    \n",
    "    #use this for jupyter notebook\n",
    "    config_file = os.path.join(r'C:\\GitHub\\fire_incidents', filename)\n",
    "    \n",
    "    #use this for .py script execution\n",
    "    #dictionary_file = os.path.join(Path(os.path.dirname(os.path.abspath(__file__))), filename)\n",
    "    \n",
    "    file = open(r'C:\\GitHub\\fire_incidents\\default_dimensions.txt', \"r\")\n",
    "    #file = open(r'C:\\GitHub\\fire_incidents\\compound_dimensions.txt', \"r\")\n",
    "    #file = open(dictionary_file, \"r\")\n",
    "\n",
    "    contents = file.read()\n",
    "    dictionary = ast.literal_eval(contents)\n",
    "\n",
    "    return(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sodapy import Socrata\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client_name = get_param('API','client_name')\n",
    "file_name = get_param('API','file_name')\n",
    "#limit_size = get_param('API','limit_size')\n",
    "limit_size = 2000\n",
    "\n",
    "print(client_name)\n",
    "print(file_name)\n",
    "print(limit_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = Socrata(client_name, None)\n",
    "results = client.get(file_name, limit=limit_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_records(results)\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.replace('sytem', 'system')\n",
    "source_data = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mysql_connection():\n",
    "    \n",
    "    #Recovering DB parameters\n",
    "    hostname = get_param('DB', 'mysql_hostname')\n",
    "    db_name = get_param('DB', 'db_name')\n",
    "    user_name= get_param('DB', 'user_name')\n",
    "    pwd = get_param('DB', 'pwd')\n",
    "\n",
    "    #Building connection_string\n",
    "    db_connection_str = 'mysql+mysqlconnector://'+user_name+':'+pwd+'@'+hostname+'/'+db_name\n",
    "    db_connection = sqlalchemy.create_engine(db_connection_str)\n",
    "\n",
    "    return db_connection\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "def refresh_db(database_name):\n",
    "    engine = create_mysql_connection() # connect to server\n",
    "    engine.execute(\"DROP DATABASE IF EXISTS \" + database_name + \";\") #drop db if exists\n",
    "    engine.execute(\"CREATE DATABASE \" + database_name + \";\") #create db\n",
    "    engine.execute(\"USE \" + database_name + \";\") # select new db\n",
    "    \n",
    "###########################################################################################    \n",
    "\n",
    "def read_table_to_df(dim):\n",
    "    #db_connection = create_mysql_connection\n",
    "    hostname = get_param('DB', 'mysql_hostname')\n",
    "    db_name = get_param('DB', 'db_name')\n",
    "    user_name= get_param('DB', 'user_name')\n",
    "    pwd = get_param('DB', 'pwd')\n",
    "    \n",
    "    db_connection = mysql.connector.connect(\n",
    "        host= hostname,\n",
    "        user = user_name,\n",
    "        password = pwd,\n",
    "        database = db_name\n",
    "        )\n",
    "    query = \"select * FROM \" + dim\n",
    "    return pd.read_sql(query, con=db_connection)\n",
    "\n",
    "###########################################################################################\n",
    "\n",
    "def load_table(table_name, df, table_action):\n",
    "    db_connection = create_mysql_connection()\n",
    "    df.to_sql(name=table_name, con=db_connection, index=False, if_exists=table_action)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dim_by_column(source_data, dim_name, column_name, base_id):\n",
    "    df=source_data\n",
    "    clean_df1 = df[column_name].drop_duplicates(inplace=False).sort_values().reset_index(drop=True).dropna().to_frame()\n",
    "    clean_df1['Id'] = clean_df1.index + base_id + 1\n",
    "    dim_df = clean_df1[['Id',column_name]]\n",
    "    final_df = dim_df.rename(columns = {column_name: dim_name + '_desc'}, inplace = False)\n",
    "    return final_df    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_file = get_param('DIM','default')\n",
    "dim_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dim = get_dictionary(dim_file)\n",
    "\n",
    "created_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in default_dim:\n",
    "    if default_dim[key] in source_data:\n",
    "        \n",
    "        df_dimensionado = dim_by_column(source_data, key, default_dim[key], 0)\n",
    "        df_clean = df_dimensionado.dropna()\n",
    "        load_table('dim_' + key, df_clean, 'replace')\n",
    "        created_dims.append(key)\n",
    "    else:\n",
    "        raise Exception(\"ERROR: The column \"+ default_dim[key] + \" does not exist - Verify and correct \" + dim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy = source_data\n",
    "copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if len(default_dim) != len(created_dims):\n",
    "    raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "        Dimension List: \"+ ','.join(list(default_dim.keys()))+ \"\\nCreated Dimensions\" \\\n",
    "            + ','.join(created_dims))\n",
    "else:\n",
    "    print(created_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####TEST COMPOUND DIMENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_file = get_param('DIM','compound')\n",
    "compound_dim = get_dictionary(dim_file)\n",
    "\n",
    "created_dims = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in compound_dim:\n",
    "    i = 1\n",
    "    \n",
    "    for column_name in compound_dim[key]:\n",
    "        if column_name in source_data:\n",
    "            if i == 1:\n",
    "                df_acum = dim_by_column(source_data, key, column_name, 0)\n",
    "                \n",
    "                \n",
    "            else:\n",
    "                base_id = len(df_acum.index)\n",
    "                df_acum = pd.concat([df_acum, dim_by_column(source_data, key, column_name, base_id)], ignore_index=True)\n",
    "               \n",
    "               \n",
    "                new_column_name = key + '_desc'\n",
    "                df_acum = df_acum[new_column_name].drop_duplicates(inplace=False).sort_values().reset_index(drop=True).dropna().to_frame()\n",
    "        \n",
    "            i += 1\n",
    "        else:\n",
    "            raise Exception(\"ERROR: The column \"+ column_name + \" does not exist - Verify and correct \" + dim_file)\n",
    "    clean_df = df_acum.dropna()\n",
    "    clean_df['Id'] = clean_df.index + 1\n",
    "    column_list = ['Id', new_column_name]\n",
    "    final_df = clean_df[column_list]\n",
    "    load_table('dim_' + key, final_df, 'replace')\n",
    "    created_dims.append(key)\n",
    "\n",
    "if len(compound_dim) != len(created_dims):\n",
    "    raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "        Dimension List: \"+ ','.join(list(compound_dim.keys()))+ \"\\nCreated Dimensions\" \\\n",
    "            + ','.join(created_dims))\n",
    "    \n",
    "else:\n",
    "    print(\"Todo salio piola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###FIN TEST COMPOUND DIMENSIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### INICIO TESTS FACT_TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "      incident_number exposure_number        id  \\\n0             8028304               0  80283040   \n1             8028303               0  80283030   \n2             8028309               0  80283090   \n3             8028314               0  80283140   \n4             8028319               0  80283190   \n...               ...             ...       ...   \n1995          3002285               0  30022850   \n1996          3002484               0  30024840   \n1997          3002485               0  30024850   \n1998          3002490               0  30024900   \n1999          3002491               0  30024910   \n\n                            address incident_date call_number  \\\n0                     150 Elsie St.    2008-04-01   080920257   \n1                     85 Turner Tr.    2008-04-01   080920256   \n2                       175 6th St.    2008-04-01   080920262   \n3                     633 Hayes St.    2008-04-01   080920268   \n4           27th Av. / Cabrillo St.    2008-04-01   080920273   \n...                             ...           ...         ...   \n1995                3400 Laguna St.    2003-01-08   030080049   \n1996        23rd St. / Shotwell St.    2003-01-08   030080381   \n1997  23rd St. / South Van Ness Av.    2003-01-08   030080382   \n1998                  100 Cargo Wy.    2003-01-08   030080387   \n1999             2985 San Bruno Av.    2003-01-08   030080388   \n\n              alarm_dttm        arrival_dttm          close_dttm city  ...  \\\n0    2008-04-01 18:06:37 2008-04-01 18:15:19 2008-04-01 18:21:48   SF  ...   \n1    2008-04-01 18:00:52 2008-04-01 18:06:30 2008-04-01 18:22:18   SF  ...   \n2    2008-04-01 18:42:06 2008-04-01 18:45:23 2008-04-01 18:53:25   SF  ...   \n3    2008-04-01 19:03:52 2008-04-01 19:08:39 2008-04-01 19:35:36   SF  ...   \n4    2008-04-01 19:16:12 2008-04-01 19:23:48 2008-04-01 19:28:49   SF  ...   \n...                  ...                 ...                 ...  ...  ...   \n1995 2003-01-08 06:37:40 2003-01-08 06:41:23 2003-01-08 06:48:05   SF  ...   \n1996 2003-01-08 22:29:30 2003-01-08 22:31:51 2003-01-08 23:40:56   SF  ...   \n1997 2003-01-08 22:30:22 2003-01-08 22:32:28 2003-01-08 22:32:28   SF  ...   \n1998 2003-01-08 22:47:14 2003-01-08 22:50:34 2003-01-08 22:53:45   SF  ...   \n1999 2003-01-08 22:49:08 2003-01-08 22:51:49 2003-01-08 23:21:42   SF  ...   \n\n     detector_type detector_operation detector_effectiveness  \\\n0                                                              \n1                                                              \n2                                                              \n3                                                              \n4                                                              \n...            ...                ...                    ...   \n1995                                                           \n1996                                                           \n1997                                                           \n1998                                                           \n1999                                                           \n\n     detector_failure_reason automatic_extinguishing_system_present  \\\n0                                                                     \n1                                                                     \n2                                                                     \n3                                                                     \n4                                                                     \n...                      ...                                    ...   \n1995                                                                  \n1996                                                                  \n1997                                                                  \n1998                                                                  \n1999                                                                  \n\n     automatic_extinguishing_system_type  \\\n0                                          \n1                                          \n2                                          \n3                                          \n4                                          \n...                                  ...   \n1995                                       \n1996                                       \n1997                                       \n1998                                       \n1999                                       \n\n     automatic_extinguishing_system_perfomance  \\\n0                                                \n1                                                \n2                                                \n3                                                \n4                                                \n...                                        ...   \n1995                                             \n1996                                             \n1997                                             \n1998                                             \n1999                                             \n\n     automatic_extinguishing_system_failure_reason  \\\n0                                                    \n1                                                    \n2                                                    \n3                                                    \n4                                                    \n...                                            ...   \n1995                                                 \n1996                                                 \n1997                                                 \n1998                                                 \n1999                                                 \n\n     number_of_sprinkler_heads_operating box  \n0                                             \n1                                             \n2                                             \n3                                             \n4                                             \n...                                  ...  ..  \n1995                                          \n1996                                          \n1997                                          \n1998                                          \n1999                                          \n\n[2000 rows x 64 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>incident_number</th>\n      <th>exposure_number</th>\n      <th>id</th>\n      <th>address</th>\n      <th>incident_date</th>\n      <th>call_number</th>\n      <th>alarm_dttm</th>\n      <th>arrival_dttm</th>\n      <th>close_dttm</th>\n      <th>city</th>\n      <th>...</th>\n      <th>detector_type</th>\n      <th>detector_operation</th>\n      <th>detector_effectiveness</th>\n      <th>detector_failure_reason</th>\n      <th>automatic_extinguishing_system_present</th>\n      <th>automatic_extinguishing_system_type</th>\n      <th>automatic_extinguishing_system_perfomance</th>\n      <th>automatic_extinguishing_system_failure_reason</th>\n      <th>number_of_sprinkler_heads_operating</th>\n      <th>box</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8028304</td>\n      <td>0</td>\n      <td>80283040</td>\n      <td>150 Elsie St.</td>\n      <td>2008-04-01</td>\n      <td>080920257</td>\n      <td>2008-04-01 18:06:37</td>\n      <td>2008-04-01 18:15:19</td>\n      <td>2008-04-01 18:21:48</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>8028303</td>\n      <td>0</td>\n      <td>80283030</td>\n      <td>85 Turner Tr.</td>\n      <td>2008-04-01</td>\n      <td>080920256</td>\n      <td>2008-04-01 18:00:52</td>\n      <td>2008-04-01 18:06:30</td>\n      <td>2008-04-01 18:22:18</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8028309</td>\n      <td>0</td>\n      <td>80283090</td>\n      <td>175 6th St.</td>\n      <td>2008-04-01</td>\n      <td>080920262</td>\n      <td>2008-04-01 18:42:06</td>\n      <td>2008-04-01 18:45:23</td>\n      <td>2008-04-01 18:53:25</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8028314</td>\n      <td>0</td>\n      <td>80283140</td>\n      <td>633 Hayes St.</td>\n      <td>2008-04-01</td>\n      <td>080920268</td>\n      <td>2008-04-01 19:03:52</td>\n      <td>2008-04-01 19:08:39</td>\n      <td>2008-04-01 19:35:36</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>8028319</td>\n      <td>0</td>\n      <td>80283190</td>\n      <td>27th Av. / Cabrillo St.</td>\n      <td>2008-04-01</td>\n      <td>080920273</td>\n      <td>2008-04-01 19:16:12</td>\n      <td>2008-04-01 19:23:48</td>\n      <td>2008-04-01 19:28:49</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1995</th>\n      <td>3002285</td>\n      <td>0</td>\n      <td>30022850</td>\n      <td>3400 Laguna St.</td>\n      <td>2003-01-08</td>\n      <td>030080049</td>\n      <td>2003-01-08 06:37:40</td>\n      <td>2003-01-08 06:41:23</td>\n      <td>2003-01-08 06:48:05</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1996</th>\n      <td>3002484</td>\n      <td>0</td>\n      <td>30024840</td>\n      <td>23rd St. / Shotwell St.</td>\n      <td>2003-01-08</td>\n      <td>030080381</td>\n      <td>2003-01-08 22:29:30</td>\n      <td>2003-01-08 22:31:51</td>\n      <td>2003-01-08 23:40:56</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1997</th>\n      <td>3002485</td>\n      <td>0</td>\n      <td>30024850</td>\n      <td>23rd St. / South Van Ness Av.</td>\n      <td>2003-01-08</td>\n      <td>030080382</td>\n      <td>2003-01-08 22:30:22</td>\n      <td>2003-01-08 22:32:28</td>\n      <td>2003-01-08 22:32:28</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1998</th>\n      <td>3002490</td>\n      <td>0</td>\n      <td>30024900</td>\n      <td>100 Cargo Wy.</td>\n      <td>2003-01-08</td>\n      <td>030080387</td>\n      <td>2003-01-08 22:47:14</td>\n      <td>2003-01-08 22:50:34</td>\n      <td>2003-01-08 22:53:45</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>1999</th>\n      <td>3002491</td>\n      <td>0</td>\n      <td>30024910</td>\n      <td>2985 San Bruno Av.</td>\n      <td>2003-01-08</td>\n      <td>030080388</td>\n      <td>2003-01-08 22:49:08</td>\n      <td>2003-01-08 22:51:49</td>\n      <td>2003-01-08 23:21:42</td>\n      <td>SF</td>\n      <td>...</td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n<p>2000 rows × 64 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 273
    }
   ],
   "source": [
    "source_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dims(source_data):\n",
    "\n",
    "    try:\n",
    "        load_default_dims(source_data)\n",
    "    except:\n",
    "        log = logging.getLogger()\n",
    "        log.exception(\"Log Exception Message - Default Dims\")\n",
    "        print(\"An error occurred while loading default dimensions\")\n",
    "\n",
    "    try:\n",
    "        load_compound_dims(source_data)\n",
    "    except:\n",
    "        log = logging.getLogger()\n",
    "        log.exception(\"Log Exception Message - Compound Dims\")\n",
    "        print(\"An error occurred while loading compound dimensions\")\n",
    "\n",
    "    return 0\n",
    "\n",
    "\n",
    "def load_default_dims(source_data):\n",
    "    \n",
    "    dim_file = get_param('DIM','default')\n",
    "    default_dim = get_dictionary(dim_file)\n",
    "\n",
    "    created_dims = []\n",
    "\n",
    "    for key in default_dim:\n",
    "        if default_dim[key] in source_data:\n",
    "            df = dim_by_column(source_data, key, default_dim[key], 0)\n",
    "            clean_df = df.dropna()\n",
    "            try:\n",
    "                load_table('dim_' + key, clean_df, 'replace')\n",
    "            except:\n",
    "                print(\"An error occurred while loading default dimension \" + key)\n",
    "            created_dims.append(key)\n",
    "        else:\n",
    "            raise Exception(\"ERROR: The column \"+ default_dim[key] + \" does not exist - Verify and correct \" + dim_file)\n",
    "\n",
    "    if len(default_dim) != len(created_dims):\n",
    "        raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "            Dimension List: \"+ ','.join(list(default_dim.keys()))+ \"\\nCreated Dimensions\" \\\n",
    "                + ','.join(created_dims))\n",
    "    else:\n",
    "        print(\"Default dims created: \" + ', '.join(created_dims))\n",
    "        return created_dims     \n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "def load_compound_dims(source_data):\n",
    "    \n",
    "    dim_file = get_param('DIM','compound')\n",
    "    compound_dim = get_dictionary(dim_file)\n",
    "\n",
    "    created_dims = []\n",
    "\n",
    "    for key in compound_dim:\n",
    "        i = 1\n",
    "        for column_name in compound_dim[key]:\n",
    "            if column_name in source_data:\n",
    "                if i == 1:\n",
    "                    df_acum = dim_by_column(source_data, key, column_name, 0)\n",
    "                else:\n",
    "                    base_id = len(df_acum.index)\n",
    "                    df_acum = pd.concat([df_acum, dim_by_column(source_data, key, column_name, base_id)], ignore_index=True)\n",
    "                    new_column_name = key + '_desc'\n",
    "                    df_acum = df_acum[new_column_name].drop_duplicates(inplace=False).sort_values().reset_index(drop=True).dropna().to_frame()\n",
    "                i += 1\n",
    "            else:\n",
    "                raise Exception(\"ERROR: The column \"+ column_name + \" does not exist - Verify and correct \" + dim_file)\n",
    "        clean_df = df_acum.dropna()\n",
    "        clean_df['Id'] = clean_df.index + 1\n",
    "        column_list = ['Id', new_column_name]\n",
    "        final_df = clean_df[column_list]\n",
    "        load_table('dim_' + key, final_df, 'replace')\n",
    "        created_dims.append(key)\n",
    "\n",
    "    if len(compound_dim) != len(created_dims):\n",
    "        raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "            Dimension List: \"+ ','.join(list(compound_dim.keys()))+ \"\\nCreated Dimensions\" \\\n",
    "                + ','.join(created_dims))\n",
    "    else:\n",
    "        print(\"Compound dims created: \" + ', '.join(created_dims))\n",
    "        return created_dims\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "def dim_by_column(df, dim_name, column_name, base_id):\n",
    "    \n",
    "    #This function returns a pandas dataframe with a sequential autogenerated Id and the attribute to be dimensioned\n",
    "    clean_df = df[column_name].drop_duplicates(inplace=False).sort_values().reset_index(drop=True).dropna().to_frame()\n",
    "    clean_df['Id'] = clean_df.index + base_id + 1\n",
    "    dim_df = clean_df[['Id',column_name]]\n",
    "    final_df = dim_df.rename(columns = {column_name: dim_name + '_desc'}, inplace = False)\n",
    "    return final_df\n",
    "    \n",
    "######################################################################################################################################\n",
    "\n",
    "def replace_attr_id(df, dim):\n",
    "    #df_dim = read_table_to_df(dim)\n",
    "\n",
    "    #fact left_join dim replace attr with id\n",
    "    replaced_df = ''\n",
    "    return replaced_df\n",
    "\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def lookup_default_dim(df):\n",
    "    \n",
    "    dim_file = get_param('DIM','default')\n",
    "    default_dim = get_dictionary(dim_file)\n",
    "\n",
    "    replaced_dims = []\n",
    "\n",
    "    for key in default_dim:\n",
    "        if default_dim[key] in df:\n",
    "            table_name = \"dim_\" + key\n",
    "            dim_df = read_table_to_df(table_name)\n",
    "            replaced_df = replace_attrib_for_id(df, dim_df, default_dim[key], key + \"_desc\")\n",
    "            replaced_dims.append(key)\n",
    "        else:\n",
    "            raise Exception(\"ERROR: The column \"+ default_dim[key] + \" does not exist - Verify and correct \" + dim_file)\n",
    "    \n",
    "    if len(default_dim) != len(replaced_dims):\n",
    "        raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "            Dimension List: \"+ ','.join(list(default_dim.keys()))+ \"\\nCreated Dimensions\" \\\n",
    "                + ','.join(replaced_dims))\n",
    "    \n",
    "    return replaced_df\n",
    "\n",
    "#######################################################################################################################################\n",
    "\n",
    "def lookup_compound_dim(df):\n",
    "    \n",
    "    dim_file = get_param('DIM','compound')\n",
    "    compound_dim = get_dictionary(dim_file)\n",
    "\n",
    "    replaced_dims = []\n",
    "    \n",
    "    for key in compound_dim:\n",
    "        table_name = \"dim_\" + key\n",
    "        dim_df = read_table_to_df(table_name)\n",
    "            \n",
    "        for column_name in compound_dim[key]:\n",
    "            if column_name in df:\n",
    "                replaced_df = replace_attrib_for_id(df, dim_df, column_name, key + \"_desc\")\n",
    "                    \n",
    "            else:\n",
    "                raise Exception(\"ERROR: The column \"+ column_name + \" does not exist - Verify and correct \" + dim_file)\n",
    "        replaced_dims.append(key)\n",
    "    \n",
    "    if len(compound_dim) != len(replaced_dims):\n",
    "            print(len(compound_dim))\n",
    "            print(len(replaced_dims))\n",
    "            raise Exception(\"ERROR: there were some dimensions that couldn't been created - \\n \\\n",
    "                Dimension List: \"+ ','.join(list(compound_dim.keys()))+ \"\\nCreated Dimensions: \" \\\n",
    "                    + ','.join(replaced_dims))\n",
    "    \n",
    "    return replaced_df\n",
    "\n",
    "######################################################################################################################################\n",
    "\n",
    "def replace_attrib_for_id(source_df, dim_df, column_name, dim_column):\n",
    "    if dim_column == 'battalion_desc':\n",
    "        joined_df = pd.merge(source_df, dim_df, left_on = column_name, right_on = dim_column, how='left')\n",
    "        \n",
    "        joined_df[column_name] = joined_df['Id']\n",
    "        print(joined_df['battalion'].unique())\n",
    "        #print(joined_df[column_name])\n",
    "        #joined_df[column_name] = np.where(joined_df['_merge'] != 'left_only', joined_df['Id'], joined_df[column_name])\n",
    "        #joined_df.loc[~joined_df[dim_column].isna(), column_name].replace(joined_df['Id'],inplace=True, regex=True)\n",
    "        #replaced_df[replaced_df['city'].isna()]\n",
    "        #replaced_df[~(replaced_df['city']).isna()]\n",
    "        replaced_df = joined_df.drop(columns=['Id'])\n",
    "        replaced_df = replaced_df.drop(columns=[dim_column])\n",
    "        #, dim_column])\n",
    "        #print(replaced_df['Id'])\n",
    "        #print(replaced_df['_merge'].unique())\n",
    "    else:\n",
    "        return source_df\n",
    "    return replaced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(table_name, df, table_action):\n",
    "    db_connection = create_mysql_connection()\n",
    "    df.to_sql(name=table_name, con=db_connection, index=False, if_exists=table_action)\n",
    "\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "def load_fact(df):\n",
    "    \n",
    "    try:\n",
    "        fact_df = lookup_default_dim(df)\n",
    "        #fact_df = lookup_compound_dim(df)\n",
    "        #print(fact_df['battalion'])\n",
    "        #fact_df.fillna('', inplace=True)\n",
    "        fact_df['incident_number'] = fact_df['incident_number'].astype(int)\n",
    "        fact_df['id'] = fact_df['id'].astype(int)\n",
    "        fact_df['incident_date']= pd.to_datetime(fact_df['incident_date'])\n",
    "        fact_df['alarm_dttm']= pd.to_datetime(fact_df['alarm_dttm'])\n",
    "        fact_df['arrival_dttm']= pd.to_datetime(fact_df['arrival_dttm'])\n",
    "        fact_df['close_dttm']= pd.to_datetime(fact_df['close_dttm'])\n",
    "        fact_df['point'] = fact_df['point'].astype(str)\n",
    "        print(fact_df['battalion'])\n",
    "        #load_table('fact_fire_incidents', fact_df, 'replace')\n",
    "    except:\n",
    "        log = logging.getLogger()\n",
    "        log.exception(\"Log Exception Message - Default Dims\")\n",
    "        print(\"An error occurred while loading fact table\")\n",
    "\n",
    "    return print(\"Fact table loaded!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[ 6 10  3  2  7  5  1  8  9  4 11]\n0       B06\n1       B10\n2       B03\n3       B02\n4       B07\n       ... \n1995    B04\n1996    B06\n1997    B06\n1998    B10\n1999    B10\nName: battalion, Length: 2000, dtype: object\nFact table loaded!!!\n"
    }
   ],
   "source": [
    "import logging\n",
    "try:\n",
    "    load_fact(source_data)\n",
    "except:\n",
    "    log = logging.getLogger()\n",
    "    log.exception(\"Log Exception Message - Default Fact\")"
   ]
  }
 ]
}